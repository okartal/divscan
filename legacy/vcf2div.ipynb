{
 "metadata": {
  "name": "",
  "signature": "sha256:20bf44c23c8a83f06b29342e3931fceabc7ab1bc9fc8f8fd0ffb7019a841abdd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%writefile vcf2div.py\n",
      "#!/usr/bin/env python\n",
      "\n",
      "import sys\n",
      "import numpy as np\n",
      "from itertools import tee, izip, chain\n",
      "from scipy.special import xlogy\n",
      "import csv\n",
      "\n",
      "def jsd(distributions=None, weights=None):\n",
      "    \"\"\" Calculates the Jensen-Shannon Divergence.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    d : array_like\n",
      "        d.shape = (k,n)\n",
      "        n distributions over k-dimensional sample space\n",
      "    w : array_like\n",
      "        w.shape = (n,)\n",
      "        weights for n distributions\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    j : float\n",
      "        Jensen-Shannon Divergence between the distributions\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The Jensen-Shannon Divergence is given by J = H(<P>) - <H>, the\n",
      "    entropy of the weighted average distribution minus the weighted\n",
      "    average of the distribution entropies. It is a measure of the\n",
      "    overall difference between distributions based on information\n",
      "    loss.\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    d = distributions\n",
      "    \n",
      "    if not weights:\n",
      "        w = np.ones_like(distributions[0,:])/distributions.shape[1]\n",
      "    else:\n",
      "        w = weights\n",
      "\n",
      "    dAvg = d.dot(w)\n",
      "    h_dAvg = -xlogy(dAvg, dAvg).sum()\n",
      "    hAvg = -xlogy(w*d, d).sum()\n",
      "    return h_dAvg - hAvg\n",
      "\n",
      "def data_to_pmf(stream, field='GP', scale=None):\n",
      "    \"\"\"\n",
      "    \"\"\"\n",
      "    #rescale = lambda q: 1 - 10**(-q/10.0)    \n",
      "    for row in stream:\n",
      "        index = row[0].split(':').index(field)\n",
      "        prob_field = map(lambda x: x.split(':')[index], row[1:])\n",
      "        pmf_list = [map(float, p.split(',')) for p in prob_field]\n",
      "        if scale:\n",
      "            assert scale.lower() == 'phred' # FIXME\n",
      "            #np.asarray(pmf_list).sum(axis=1)\n",
      "            #pmf_list = [qual/totalQ for pmf in pmf_list]\n",
      "        yield pmf_list\n",
      "\n",
      "def emit_jsd(stream, population=None, subpopulations=None, weights=None):\n",
      "    for row in stream:\n",
      "        pmf = np.array(row, dtype=np.float)\n",
      "        pmf = pmf.T\n",
      "        \n",
      "        if subpopulations:\n",
      "            div = np.zeros(len(subpopulations))\n",
      "            for n, subpop in enumerate(subpopulations):\n",
      "                msk = np.array([i in subpop for i in population])\n",
      "                div[n] = jsd(distributions=pmf[:, msk])\n",
      "            if len(div) > 1:\n",
      "                div_it = div[-1]\n",
      "                div_is = div[:-1]\n",
      "                div_st = div_it - np.average(div_is, weights=weights)\n",
      "                div = np.hstack((div, div_st))\n",
      "        else:\n",
      "            div = [jsd(distributions=pmf)]\n",
      "        \n",
      "        div = np.around(div, decimals=3)\n",
      "        yield ['{:.3f}'.format(i) for i in div]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "\n",
      "    import argparse\n",
      "    \n",
      "    parser = argparse.ArgumentParser(description=\"Calculate Methylation Diversity using Jensen-Shannon Divergence.\")\n",
      "    parser.add_argument('vcf',\n",
      "                        help='input file in VCF format')\n",
      "    parser.add_argument('--prob', default='GP', required=True,\n",
      "                        help='format field ID in VCF file with posterior probabilities')\n",
      "    parser.add_argument('--scale', default=None, choices=['phred'], required=False,\n",
      "                        help='scale of posterior probabilities')\n",
      "    parser.add_argument('-o', '--outfile', default='div.txt', required=False,\n",
      "                        help='output file in BED-like format, for N subpopulations the divergence values are given in the order (IS-1 ... IS-N, IT, ST)')\n",
      "    parser.add_argument('-p', '--subpopulations', required=False,\n",
      "                        help='input file with subpopulations as defined by tab-separated line of sample IDs from VCF file')\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    subpops = None\n",
      "    weight_subpops = None\n",
      "\n",
      "    if args.subpopulations:\n",
      "        with open(args.subpopulations, 'rb') as f:\n",
      "            subpops = f.readlines()\n",
      "            subpops = [row.strip().split('\\t') for row in subpops]\n",
      "            if len(subpops) > 1:\n",
      "                size_subpops = np.array(map(len, subpops))\n",
      "                weight_subpops = size_subpops/np.float(size_subpops.sum())\n",
      "                whole_subpop = list(chain.from_iterable(subpops))\n",
      "                subpops.append(whole_subpop)\n",
      "\n",
      "    with open(args.vcf, 'rb') as vcf:\n",
      "        post_meta = (row.strip().split('\\t') for row in vcf if not row.startswith('##'))\n",
      "        head = map(str.upper, post_meta.next())\n",
      "        data = (row for row in post_meta if row[head.index('REF')] != 'N')\n",
      "        locus_stream, pop_stream  = tee(data, 2)\n",
      "        locus_stream = (row[:2] + [row[7]] for row in locus_stream)\n",
      "        pop_stream = (row[8:] for row in pop_stream)\n",
      "        pop_stream = data_to_pmf(pop_stream, field=args.prob, scale=args.scale)    \n",
      "        pop_stream = emit_jsd(pop_stream, population=head[9:], subpopulations=subpops, weights=weight_subpops)\n",
      "\n",
      "        with open(args.outfile, 'wb') as f:\n",
      "            writer = csv.writer(f, delimiter='\\t')\n",
      "            output_stream = izip(locus_stream, pop_stream)\n",
      "            result = (list(chain.from_iterable(row)) for row in output_stream)\n",
      "            writer.writerows(result)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "usage: -c [-h] --prob PROB [--scale {phred}] [-o OUTFILE] [-p SUBPOPULATIONS]\n",
        "          vcf\n",
        "-c: error: argument --prob is required\n"
       ]
      },
      {
       "ename": "SystemExit",
       "evalue": "2",
       "output_type": "pyerr",
       "traceback": [
        "An exception has occurred, use %tb to see the full traceback.\n",
        "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "To exit: use 'exit', 'quit', or Ctrl-D.\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "vcf_path = 'bmeth-tab.meth.vcf'\n",
      "\n",
      "with open(vcf_path, 'rb') as vcf:\n",
      "    for n, line in enumerate(vcf):\n",
      "        if not line.startswith('##') and line.startswith('#'):\n",
      "            header = line.strip().lower().split('\\t')\n",
      "            ncols = len(header)\n",
      "            sample_cols = range(header.index('format') + 1, ncols)\n",
      "            comments = n\n",
      "            break\n",
      "\n",
      "\n",
      "vcf = pd.read_table(vcf_path, header=0, nrows=5000, skiprows=comments, na_values='./.')\n",
      "vcf.dropna(axis=0, inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rescale = lambda q: 10**(-float(q)/10.0)\n",
      "\n",
      "def extract(data):\n",
      "    counts = data.split(':')[3:6:2] # M, nonM read counts\n",
      "    if counts[0] == '.' or counts[1] == '.':\n",
      "        return np.nan\n",
      "    else:\n",
      "    #pmflist = np.asarray([f.split(',') for f in data.split(':')][8], dtype=float)\n",
      "        counts = np.asarray(counts, dtype=float)\n",
      "        return counts/counts.sum()\n",
      "    \n",
      "def extract2(data):\n",
      "    qual = np.asarray([f.split(',') for f in data.split(':')][8], dtype=float)\n",
      "    return qual/qual.sum() #qualities as proxies for posterior\n",
      "\n",
      "df = vcf.icol(sample_cols).applymap(extract2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# iterating over rows of df to calculate jsd\n",
      "x = df.iterrows()\n",
      "div = [jsd(r[1].apply(pd.Series).values.T) for r in x]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "div[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 226,
       "text": [
        "[0.013272263806440199,\n",
        " 0.013406154463261433,\n",
        " 0.013692868128334812,\n",
        " 0.016663907161747371,\n",
        " 0.01021758439077769,\n",
        " 0.0091816595196367867,\n",
        " 0.0067469900137298033,\n",
        " 0.010328140200229985,\n",
        " 0.0095483239795489672,\n",
        " 0.027770241092547221]"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alphabet = 'ACGT'\n",
      "ploidy = 2\n",
      "genotype_space = it.combinations_with_replacement(alphabet, ploidy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_prob(data=None, sample_space=None, ploidy=None):\n",
      "    for line in data:\n",
      "\n",
      "        # extract the present alleles and encode them according to VCF specs,\n",
      "        # construct the possible genotypes and sort them according to the VCF-GL format field\n",
      "        \n",
      "        alleles = str.upper(line[3] + ''.join(line[4].split(',')))\n",
      "        allele_code = range(len(alleles))\n",
      "        \n",
      "        gt_code = it.combinations_with_replacement(allele_code, ploidy)\n",
      "        vcf_sort = lambda x: x[0] + (x[1]*(x[1] + 1)/2)\n",
      "        gt_code_sorted = sorted(gt_code, key=vcf_sort)\n",
      "        genotypes = map(lambda x: ''.join([alleles[k] for k in x]), gt_code_sorted)\n",
      "        genotypes.pop() # dummy to make test work REMOVE!\n",
      "        \n",
      "        # build the pmf for genotype probabilities ('GP') according to the given sample space\n",
      "        \n",
      "        prob_ind = line[8].split(':').index('AP')\n",
      "        probs = np.array(map(lambda x: x.split(':')[prob_ind].split(','), line[9:]))\n",
      "        \n",
      "        popsize = probs.shape[0]\n",
      "        pmf = np.zeros((popsize, len(sample_space)))\n",
      "        \n",
      "        ind = [sample_space.index(gt) for gt in genotypes]\n",
      "        pmf[:, ind] = probs\n",
      "        \n",
      "        yield str(pmf.sum())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# writing a test pop file\n",
      "\n",
      "with open('test.vcf') as vcf:\n",
      "    data_h = (line.strip().split('\\t') for line in vcf if not line.startswith('##'))\n",
      "    header = data_h.next()      \n",
      "    sample_id = header[9:]\n",
      "    import random\n",
      "    with open('test.pop', 'w') as pop:\n",
      "        for i in range(4):\n",
      "            n = random.randint(1,10)\n",
      "            pop.writelines('\\t'.join(random.sample(sample_id, n)) + '\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    }
   ],
   "metadata": {}
  }
 ]
}