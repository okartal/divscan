#!/usr/bin/env python3
# -*- coding: utf-8 -*-

__author__ = 'Ã–nder Kartal'

import argparse
import io
import os
import sys

import pandas as pd
import numpy as np

from shannonlib.core import divergence


def run_divergence(args):

    if os.path.isfile(args.output) and not os.stat(args.output).st_size == 0:
        msg = "-- Stopped!\n-- Output file exists and is not empty."
        sys.exit(msg)

    meta = io.StringIO(args.metadata.read())

    try:
        sample = pd.read_csv(meta, comment='#', header=0)
        _ = sample['url']
        _ = sample['label']
    except KeyError:
        try:
            sample = pd.read_csv(meta, comment='#', header=0, sep='\t')
            _ = sample['url']
            _ = sample['label']
        except KeyError:
            msg = ('-- Stopped!\n'
                   '-- Could not parse metadata.\n'
                   '-- 1. Ensure that fields are tab- or comma-separated\n'
                   '-- 2. Ensure that columns "url" and "label" are present')
            sys.exit(msg)

    # GPF data columns
    try:
        assert(len(args.dcols) == len(args.dnames))
    except AssertionError:
        msg = ('-- Stopped!\n'
               '-- Length of --dcols and --dnames must match')
        sys.exit(msg)

    dtypes = [float if args.prob else int] * len(args.dcols)
    dcols = [col - 1 for col in args.dcols]
    gpf_data = [list(zip(dcols, args.dnames, dtypes))]

    # if groupby is not None:
    #     subsample_family = sample.groupby(groupby)
    #     for key, subsample in subsample_family:
    #         filename = groupname(by=groupby, name=key, fname=args.output)
    #         divergence(subsample, chrom=args.sequence, data_columns=gpf_data,
    #                    outfile=filename, chunksize=args.chunksize)
    # else:
    print('processing sequence {} ...'.format(args.sequence))
    divergence(sample, chrom=args.sequence, data_columns=gpf_data,
               outfile=args.output, chunksize=args.chunksize)

    return None


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    # main parser
    parser.prog = 'shannon'
    parser.description = 'Command-line interface to %(prog)s.'

    # cluster
    parser_cluster = subparsers.add_parser('cluster')

    # segment
    parser_segment = subparsers.add_parser('seg')

    # divergence
    parser_divergence = subparsers.add_parser('div')

    parser_divergence.set_defaults(func=run_divergence)
    parser_divergence.help = 'JS Divergence for each position.'
    parser_divergence.description = parser_divergence.help

    parser_divergence.add_argument(
        '--prob',
        action='store_true',
        help='flag the data as probabilites (default: counts)'
    )

    parser_divergence.add_argument(
        '-c',
        '--chunksize',
        metavar='INT',
        default=1e4,
        type=int,
        help='''
        expected number of genome positions processed in memory (default: %(default)d)
        '''
    )
    parser_divergence.add_argument(
        '-m',
        '--metadata',
        metavar='FILE',
        type=argparse.FileType('r'),
        required=True,
        help='''
        table (.csv or .tsv) with metadata; lines starting with # are ignored;
        first non-comment line must be header; "url" and "label" headers are
        required; use dash (-) instead of FILE if metadata is piped from stdin.
        '''
    )
    parser_divergence.add_argument(
        '-o',
        '--output',
        metavar='FILE',
        required=True
    )
    parser_divergence.add_argument(
        '-s',
        '--sequence',
        metavar='ID',
        required=True,
        type=str,
        help='Sequence (chromosome/scaffold) in genome position file'
    )
    parser_divergence.add_argument(
        '--dcols',
        metavar='INT',
        nargs='+',
        required=True,
        type=int,
        help='positions of data columns in genome position files'
    )
    parser_divergence.add_argument(
        '--dnames',
        metavar='STR',
        nargs='+',
        required=True,
        type=str,
        help='names of data columns in genome position files (same order as --dcols!)'
    )

    # parser.add_argument('-g', '--groupby', metavar='STR', nargs='+', type=str,
    #                     help='''
    #                     The factor according to which the selected set is
    #                     partitioned; has to match column names in the input
    #                     metadata. One or more factors can be given, which
    #                     produces a file for each combination of factors.
    #                     ''')

    args = parser.parse_args()
    args.func(args)
